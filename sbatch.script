#!/bin/bash
#SBATCH --nodes=10
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=10
#SBATCH --time=1:00:00
#SBATCH --output=slurm_%j.out


module purge
module load openmpi/gnu/4.0.2
SRCDIR=$HOME/hpc/hpc-graph-allpairs-shortestpath
cd $SRCDIR
mpic++  bfsApspMPI.cpp -o bfsApspMPI -fopenmp
#mpirun  --mca btl_tcp_if_include eth0  --np 1  --bind-to none -x OMP_NUM_THREADS=$j bfsApspMPI --serial -t 1 -p 1 -o 10000 -d 5

for (( i = 10; i <= 30; i++ ))      ### Outer for loop ###
do

    for (( j = 4 ; j <= 4; j++ )) ### Inner for loop ###
    do
        mpirun --mca btl_tcp_if_include eth0  --bind-to none -x OMP_NUM_THREADS=$j --np $i bfsApspMPI -t $j -p $i -o 10000 -d 5
    done

  echo "" #### print the new line ###
done
